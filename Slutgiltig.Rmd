---
title: "Projekt A"
author: "Olivia Buhr, Betty Frankl, August Jonasson, Sofia Näslund"
date: "2023-09-23"
output:
  pdf_document: default
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(car)
library(olsrr)
library(knitr)
library(kableExtra)
```

```{r, include=FALSE}
data <- read_table("A18-sjalv-win.dat",
                   col_names = c("län", "y1", "y2", "x51", "x41", "x52", "x42",
                                 "x11", "x12", "x61", "x62", "x21", "x22", "x3"))

data_1 <- data %>%
  select("län", "y1", "x51", "x41", "x11", "x61", "x21", "x3") %>%
  rename("län" = "län",
         "sjmo" = "y1",
         "arblösMän" = "x51",
         "arblösTot" = "x41",
         "alko" = "x11",
         "urban" = "x61",
         "skilsmässo" = "x21",
         "religio" = "x3")

data_2 <- data %>%
  select("län", "y2", "x52", "x42", "x12", "x62", "x22", "x3") %>%
  rename("län" = "län",
         "sjmo" = "y2",
         "arblösMän" = "x52",
         "arblösTot" = "x42",
         "alko" = "x12",
         "urban" = "x62",
         "skilsmässo" = "x22",
         "religio" = "x3")

save(data_1, file = "data_1.Rda")
save(data_2, file = "data_2.Rda")
```

## Models
```{r, echo=FALSE}
model_1 <- lm(sjmo ~ ., data = data_1 %>% select(!län))
model_2 <- lm(sjmo ~ ., data = data_2 %>% select(!län))
```

```{r, echo=FALSE}
load("data_1.Rda")
load("data_2.Rda")
```


\renewcommand{\tablename}{Tabell}
\renewcommand{\figurename}{Figur}



```{r, include=FALSE}
# Bettys functions

basic_plots <- function(data, model, title) {
  par(mfrow = c(2,3), mar = c(5,4,4,2), oma = c(0,0,2,0), cex.lab=0.9)
  plot(data$arblös_män, data$sjmo,
       xlab = "arbetslöshetsindex män",
       ylab = "självmordsfrekvens",
       main = "Arbetslöshet män")
  plot(data$arblös_tot, data$sjmo,
       xlab = "arbetslöshetsindex total",
       ylab = "",
       main = "Arbetslöshet total")
  plot(data$alko, data$sjmo,
       xlab = "alkoholindex",
       ylab = "",
       main = "Alkohol")
  plot(data$urban, data$sjmo,
       xlab = "urbaniseringsindex",
       ylab = "självmordsfrekvens",
       main = "Urbanisering")
  plot(data$skilsmässo, data$sjmo,
       xlab = "skilsmässoindex",
       ylab = "",
       main = "Skilsmässor")
  plot(data$religio, data$sjmo,
       xlab = "religiositetsindex",
       ylab = "",
       main = "Religiositet")
  
  mtext(title, side = 3, line = -1, outer = TRUE, font = 2)
}

plot_predicted_residuals <- function(multi_model, title) {
  plot(multi_model$fitted.values, multi_model$residuals,
       xlab = "predikterade värden",
       ylab = "residualer",
       main = title)
  abline(0,0, col = "#0299b0", lwd=1.4)
} 

plot_multi_residuals <- function(data, multi_model, title) {
  par(mfrow = c(2,3))
  plot(residuals(multi_model) ~ data$arblös_män, 
       xlab = "arbetslöshetsindex män",
       ylab = "residuals",
       main = "Spread of residuals")
  abline(0,0) 
  plot(residuals(multi_model) ~ data$arblös_tot, 
       xlab = "arbetslöshetsindex total",
       ylab = "residuals",
       main = "Spread of residuals")
  abline(0,0) 
  plot(residuals(multi_model) ~ data$alko, 
       xlab = "alkoholindex",
       ylab = "residuals",
       main = "Spread of residuals")
  abline(0,0) 
  plot(residuals(multi_model) ~ data$urban, 
       xlab = "urbaniseringsindex",
       ylab = "residuals",
       main = "Spread of residuals")
  abline(0,0) 
  plot(residuals(multi_model) ~ data$skilsmässo, 
       xlab = "skilsmässoindex",
       ylab = "residuals",
       main = "Spread of residuals")
  abline(0,0) 
  plot(residuals(multi_model) ~ data$religio, 
       xlab = "religiositetsindex",
       ylab = "residuals",
       main = "Spread of residuals")
  abline(0,0)
  
  mtext(title, side = 3, line = 0, outer = TRUE)
}

plot_qq <- function(multi_model, title) {
  qqnorm(residuals(multi_model), 
         xlab = "teoretiska kvantiler",
         ylab = "datakvantiler",
         main = title)
  qqline(residuals(multi_model), col = "#ad465c", lwd=1.4)
}
```

```{r, include=FALSE}
#Bettys functions
sm_arb_män1 <- lm(sjmo ~ arblösMän, data = data_1)
sm_arb_tot1 <- lm(sjmo ~ arblösTot, data = data_1)
sm_alk1 <- lm(sjmo ~ alko, data = data_1)
sm_urb1 <- lm(sjmo ~ urban, data = data_1)
sm_ski1 <- lm(sjmo ~ skilsmässo, data = data_1)
sm_rel1 <- lm(sjmo ~ religio, data = data_1)

sm_arb_män2 <- lm(sjmo ~ arblösMän, data = data_2)
sm_arb_tot2 <- lm(sjmo ~ arblösTot, data = data_2)
sm_alk2 <- lm(sjmo ~ alko, data = data_2)
sm_urb2 <- lm(sjmo ~ urban, data = data_2)
sm_ski2 <- lm(sjmo ~ skilsmässo, data = data_2)
sm_rel2 <- lm(sjmo ~ religio, data = data_2)
```


## Sammanfattning
I detta projekt har vi...

## Inledning

I det här projektet ska vi undersöka vilka faktorer som bäst kan förklara skillnader i självmordsfrekvens mellan olika län i Sverige. Det finns forskning som antyder att alkoholmissbruk kan föregå självmord, vi är därför särskilt intresserade av sambandet mellan dessa faktorer. 

Till vår hjälp har vi två dataset baserade på registerdata från svenska län under 1960-talet, med tidsperioderna 1963-65 (period 1) och 1966-1968 (period 2). Dessa dataset innehåller information från 25 län och omfattar sex variabler som tros kunna påverka självmordsfrekvensen i länen. De undersökta variablerna inkluderar:

1. Alkoholindex: genomsnittlig förbrukning av alkohol per person och år bland befolkningen över 15 år. Detta anses vara en starkt korrelerad faktor med andelen alkoholmissbrukare.
2. Skilsmässoindex: andelen skilsmässor bland män under åren 1964 respektive 1967.
3. Religiositetsindex: sammanvägning av andelen som tillhör statskyrkan och deltar i gudstjänster samt andelen som tillhör frikyrkliga samfund. Konstant för båda tidsperioderna.

4. Arbetslöshetsindex totalt: andelen arbetslösa i mitten av de två tidsperioderna.

5. Arbetslöshetsindex män: motsvarande arbetslöshet total, men endast för den manliga befolkningen.

6. Urbaniseringsindex: andelen av befolkningen som bor i tätbefolkade områden.

## Metod
För att genomföra vår undersökning kommer vi använda oss av multipel linjär regression. Självmordsfrekvens är vår responsvariabel och övriga förklarande variabler. Då vi är intresserade av att förklara just självmordsfrekvens är det lämpligt att ha just denna variabel som responsvariabel. Det bör dock tilläggas att detta inte implicerar något kausalt samband. Huruvida det är den förklarande variabeln som påverkar självmordsfrekvensen, tvärtom eller en helt annan variabel vet vi inte. Den här undersökningen syftar endast till att förklara förändringen mellan länen. 

Vi kommer analysera de två perioderna separat då det kan finnas viktiga skillnader i datan. Uppstår det någon klar möjlighet att på något sätt slå ihop perioderna så kommer vi att göra detta men vi utgår inte ifrån att detta är en möjlighet. Då vi endast har mätdata från två tidpunkter är det svårt att uttala sig om eventuell förändring över tid. Däremot kan vi upptäcka eventuella skillnader mellan de två tidsperioderna och analysera dessa. 

För att uppfylla undersökningens syfte kommer vi lägga stor vikt vid valet av multipel linjär regressionsmodell. För att ta fram en så lämplig modell som möjligt kommer vi studera och analysera datan utifrån flera olika aspekter. Vi undersöker bland annat multikolinjäritet för olika kombinationer av variabler, $R^2$ -värden hos olika modeller och p-värden för variablerna i olika modeller. Då vi är särskilt intresserade av modeller som innehåller alkoholindex som förklarande variabel, men vi undersöker även om det finns andra modeller som kan förklara variationen bättre. 


## Första observation & kolinjäritet

Det första steget i undersökningen är att observera den insamlade datan åtskilda för de olika perioderna med alla variabler inkluderade. Vi gör detta med hjälp av parvisa plottar där vi kan studera korrelation mellan alla olika variabler, både respons och förklarande. 

```{r, fig.cap = "Parvisa variabelsamband period 1"}
pairs(data_1[2:8])
```

I Figur 1 kan vi se att den totala arbetslösheten har stark positiv korrelation med arbetslöshet för män. Korrelationen mellan alkoholindex och skilsmässoindex samt urbaniseringsindex och skilmässoindex är också positiv. Det finns även en måttlig negativ korrelation mellan alkoholindex och religiositetsindex samt skilsmässoindex och religiositetsindex. 

Självmordsfrekvens verkar vara negativt korrelerad med religiositetindex samt positivt korrelerad med skiljsmässoindex och alkoholindex. Eventuell korrelation mellan självmordsfrekvens och resterande variabler är svårare att utröna. 

```{r, fig.cap = "Parvisa variabelsamband period 2"}
pairs(data_2[2:8])

```

I Figur 2 kan vi se liknande samband som i figur 1, att den totala arbetslösheten har en stark positiv korrelation med arbetslöshet för män. Korrelationen mellan alkoholindex och skilsmässoindex samt urbaniseringsindex och skilmässoindex är också positiv. Det finns även en måttlig negativ korrelation mellan alkoholindex och religiositetsindex samt skilsmässoindex och religiositetsindex. 

Till skillnad från period 1 så är självmordsfrekvens och religiositetindex inte lika tydligt negativt korrelerade för period 2. Skiljsmässoindex och alkoholindex verkar dock fortfarande ha en positiv korrelation med självmordfrekvens. Eventuell korrelation mellan självmordsfrekvens och resterande variabler är svårare att utröna, möjligtvis att det kan finnas en negativ korrelation med arbetslöshet total. Vi kan eventuellt se en antydan till ett kvadratiskt samband mellan urbaniseringsindex och självmordsfrekvens.

Den starka korrelationen mellan arbetslöshet total och arbetslöshet män var väntad då antalet arbetslösa män är en delmängd av antalet arbetslösa totalt. Detta innebär att båda dessa variabler förklarar i princip samma sak, vi kommer därför med största sannolikhet inte inkludera båda i vår slutgiltiga modell. Att inkludera starkt korrelerade förklarande variabler i en multipel regressionsmodell kan vara problematiskt då detta kan indikera kolinjäritet. Det räcker dock inte att enbart undersöka plottar, vi behöver även någon sorts mått för att avgöra graden av kolinjäritet mellan variablerna, detta kommer att undersökas vid variabelselektionen. 

## Residualer & transformation av förklarande variabler

För att undersöka vår data ytterligare kan vi studera residualerna för de multipla linjära regressionsmodellerna med alla förklarande variabler, för respektive period. Vi plottar residualer mot predikterade värden (som ges av modellen), normal QQ-plottar samt residualer mot respektive förklarande variabel. Detta ger oss information om bland annat homoskedasticitet, normalfördelning och om någon 
variabel skulle behöva transformeras. Vi börjar med att studera residualerna för 
period 1.

```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(1,2), mar = c(5,4,4,2), oma = c(0,0,2,0), cex.lab=0.9)
plot_predicted_residuals(model_1, "Mot predikterade")
plot_qq(model_1, "Normal-QQ plot")

mtext("Residualplottar för modell med alla \n förklarande variabler (period 1)", side = 3, line = 0, outer = TRUE, font = 2)
```


I Figur 3 ser vi att plotten med residualer mot predikterade värden ser bra ut, punkterna har en jämn spridning längs residualer = 0, med andra ord verkar det finnas en homoskedasticitet. Normal QQ-plotten ser också bra ut, residualerna ser approximativt normalfördelade ut.

```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(2,3), mar = c(5,4,4,2)-0.2, oma = c(0,0,2.3,0), cex.lab=0.9)
plot(residuals(model_1) ~ data_1$arblösMän, 
     xlab = "arbetslöshetsindex män",
     ylab = "residualer",
     main = "Mot arbetslöshet (män)")
abline(0,0)
plot(residuals(model_1) ~ data_1$arblösTot, 
     xlab = "arbetslöshetsindex total",
     ylab = "",
     main = "Mot arbetslöshet (total)")
abline(0,0) 
plot(residuals(model_1) ~ data_1$alko, 
     xlab = "alkoholindex",
     ylab = "",
     main = "Mot alkohol")
abline(0,0) 
plot(residuals(model_1) ~ data_1$urban, 
     xlab = "urbaniseringsindex",
     ylab = "residualer",
     main = "Mot urbanisering")
abline(0,0) 
plot(residuals(model_1) ~ data_1$skilsmässo, 
     xlab = "skilsmässoindex",
     ylab = "",
     main = "Mot skilsmässor")
abline(0,0) 
plot(residuals(model_1) ~ data_1$religio, 
     xlab = "religiositetsindex",
     ylab = "",
     main = "Mot religiositet")
abline(0,0)

mtext("Residualplottar för modell med alla förklarande variabler (period 1)", side = 3, line = -1, outer = TRUE, font = 2)
```


I Figur 4 ser vi att residualerna verkar ha en hyfsat jämn spridning runt residualer = 0, det finns inte heller några uppenbara samband mellan residualer och de förklarande variablerna. Möjligtvis att plotten med residualer mot religiositet visar ett potentiellt samband, men då vi har så få observationer är det svårt att avgöra. 

Sammantaget ser residualerna för den multipla linjära regressionsmodellen med 
samtliga förklarande variabler (period 1) bra ut. Vår bedömning är att någon transformation av responsvariabeln eller förklarande variabler inte är aktuell. 
Vi går nu vidare till att undersöka residualerna hos samma regressionsmodell 
för period 2:

```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(1,2), mar = c(5,4,4,2), oma = c(0,0,2,0), cex.lab=0.9)
plot_predicted_residuals(model_2, "Mot predikterade")
plot_qq(model_2, "Normal-QQ plot")

mtext("Residualplottar för modell med alla \n förklarande variabler (period 2)", side = 3, line = 0, outer = TRUE, font = 2)
```


I Figur 5 ser residualerna mot predikterade värden ganska bra ut, vi kan inte se någon tydlig heteroskedasticitet. Däremot finns det en antydan till icke-linjäritet (vid predikterade värden på ca. 35 till 55), då residualerna ser ut att ha en konvex form. Normal QQ-plotten ser okej ut med tanke på att vi har en begränsad mängd data. Vi bedömer därför att residualerna åtminstone ser approximativt normalfördelade ut.

```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(2,3), mar = c(5,4,4,2)-0.2, oma = c(0,0,2.3,0), cex.lab=0.9)
plot(residuals(model_2) ~ data_2$arblösMän, 
     xlab = "arbetslöshetsindex män",
     ylab = "residualer",
     main = "Mot arbetslöshet (män)")
abline(0,0)
plot(residuals(model_2) ~ data_2$arblösTot, 
     xlab = "arbetslöshetsindex total",
     ylab = "",
     main = "Mot arbetslöshet (total)")
abline(0,0) 
plot(residuals(model_2) ~ data_2$alko, 
     xlab = "alkoholindex",
     ylab = "",
     main = "Mot alkohol")
abline(0,0) 
plot(residuals(model_2) ~ data_2$urban, 
     xlab = "urbaniseringsindex",
     ylab = "residualer",
     main = "Mot urbanisering")
abline(0,0) 
plot(residuals(model_2) ~ data_2$skilsmässo, 
     xlab = "skilsmässoindex",
     ylab = "",
     main = "Mot skilsmässor")
abline(0,0) 
plot(residuals(model_2) ~ data_2$religio, 
     xlab = "religiositetsindex",
     ylab = "",
     main = "Mot religiositet")
abline(0,0)

mtext("Residualplottar för modell med alla förklarande variabler (period 2)", side = 3, line = -1, outer = TRUE, font = 2)
```


Figur 6 visar att residualerna verkar ha en hyfsat jämn spridning runt residualer = 0 för de flesta förklarande variablerna. Det finns möjligtvis något samband mellan residualerna och de förklarande variablerna för skilsmässor och religiositet. Detta är dock svårt att avgöra då vi har så få observationer. 

```{r, include=FALSE}
new_data_2 <- data_2 %>% mutate(sjmo2 = sqrt(sjmo)) 

new_model_2 <- lm(data = new_data_2, sjmo2~.)
```

### Transformation
Då vi kunde se vissa (marginella) problem med icke-linjäritet och avvikelse från normalfördelningen (figur 5) hos residualerna för period 2 vill vi undersöka om vi kan få en bättre modell genom att transformera någon variabel. Vi undersöker detta genom att transformera variabeln, och sedan återigen studera plottarna. Vi testade ett flertal transformationer både för de förklarande variabler och responsvariabeln. Den transformation som gav bäst resultat var kvadratroten ur responsvariabeln. I figur 7 kan vi se hur residualerna förändrades efter transformationen.


```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(1,2), mar = c(5,4,4,2), oma = c(0,0,2,0), cex.lab=0.9)
plot_predicted_residuals(new_model_2, "Mot predikterade")
plot_qq(new_model_2, "Normal-QQ plot")
mtext("Residualplottar för modell med alla förklarande variabler och \n kvadratroten ur självmordsfrekvensen som responsvariabel (period 2)", side = 3, line = 0, outer = TRUE, font = 2)


```


I Figur 7 kan vi se att det misstänkta sambandet i plotten för residualer mot predikterade värden i figur 5 inte längre finns kvar. Den här plotten för residualer mot predikterade värden ser dock inte helt homoskedastisk ut, spridningen ser ut att minsta till höger. Det ser även ut att finnas en viss konkav form hos residualerna, vilket kan tyda på icke-linjäritet. Normal-QQ plotten ser inte heller ut att ha förbättrats särskilt mycket i jämförelse med figur 5.


```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(2,3), mar = c(5,4,4,2)-0.2, oma = c(0,0,2.3,0), cex.lab=0.9)
plot(residuals(new_model_2) ~ new_data_2$arblösMän, 
     xlab = "arbetslöshetsindex män",
     ylab = "residualer",
     main = "Mot arbetslöshet (män)")
abline(0,0)
plot(residuals(new_model_2) ~ new_data_2$arblösTot, 
     xlab = "arbetslöshetsindex total",
     ylab = "",
     main = "Mot arbetslöshet (total)")
abline(0,0) 
plot(residuals(new_model_2) ~ new_data_2$alko, 
     xlab = "alkoholindex",
     ylab = "",
     main = "Mot alkohol")
abline(0,0) 
plot(residuals(new_model_2) ~ new_data_2$urban, 
     xlab = "urbaniseringsindex",
     ylab = "residualer",
     main = "Mot urbanisering")
abline(0,0) 
plot(residuals(new_model_2) ~ new_data_2$skilsmässo, 
     xlab = "skilsmässoindex",
     ylab = "",
     main = "Mot skilsmässor")
abline(0,0) 
plot(residuals(new_model_2) ~ new_data_2$religio, 
     xlab = "religiositetsindex",
     ylab = "",
     main = "Mot religiositet")
abline(0,0)

mtext("Residualplottar för modell med alla förklarande variabler och \nkvadratroten ur självmordsfrekvensen som responsvariabel (period 2) ", side = 3, line = -1, outer = TRUE, font = 2)
```


I Figur 8 ser vi att residualerna ser bra ut för de flesta förklarande variabler. Spridningen är hyfsat jämn runt residualer = 0 och det går inte att urskilja något tydligt samband mellan residualerna och  respektive förklarande variabel.

Det finns vissa fördelar med den modell där vi transformerade vår responsvariabel, förbättringarna var dock marginella. Den eventuella icke-linjäriteten som vi såg i figur 5 försvann men vi fick istället vissa andra problem med residualerna. Residualerna mot de förklarande variablerna såg dock bra ut. Ett annat problem som skapas när vi transformerar är att tolkningen av modellen blir mindre intuitiv. Istället för att förklara variationen hos självmordsfrekvensen förklarar vi hur kvadratroten ur självmordsfrekvensen varierar. Då vi väger samman dessa faktorer bedömer vi att det mest lämpliga i det här fallet är att behålla självmordsfrekvensen som förklarande variabel. 

## Variabelselektion 

Valet av förklarande variabler är helt centralt när vi väljer vilken modell som bäst kan besvara vår frågeställning. Det finns flera metoder för variabelselektion, vi kommer använda oss av Forward selection, Backward elimination och Stepwise regression. Detta är stegvisa metoder som bygger på att välja ut de förklarande variabler som ger högst $p$-värde i modellen. Det finns dock flera aspekter vi behöver ta hänsyn till, en av dem är förklaringsgraden, $R^2$. Notera att vi väljer $R^2$-adjusted istället för $R^2$ för att undvika överanpassning hos modellen. Då vi endast har sex potentiella förklarande variabler har vi möjligheten att undersöka alla möjliga kombinationer av variabler (63 stycken). Vi kommer därför beräkna $R^2$-adjusted för samtliga kombinationer av de förklarande variablerna och sedan välja ut de modeller med högst värde. Vi kommer även ta observera $VIF$-värdena för variablerna (variance inflation factor) som är ett mått på (multi)kolinjäritet, d.v.s. kolinjäritet mellan två eller flera variabler. Ett $VIF$-värde över fem anses ofta vara för högt, denna gräns kan dock variera beroende på t.ex. forskningsområde eller studie. Problemet med ett allt för högt $VIF$-värde är att skattningar av parametrar och $p$-värden kan bli opålitliga. Vi kommer därför studera $VIF$-värden noga när vi väljer vår modell.  


Med dessa metoder kommer vi få flera potentiella kandidater till vår modell. Därefter kommer vi granska respektive kandidat och göra en sammanvägning av $R^2$-adjusted, $p$- och $VIF$-värden för att hitta den bästa modellen. Det bör tilläggas att vi inte kommer använda oss av något mått på prediktionsförmåga hos modellen, detta eftersom syftet är att förklara snarare än att prediktera. 

Vi vill notera att vid detta tillfälle kommer vi inte ta hänsyn till inflytelserika observationer då vi inte har vidare kunskap om den insamlade datan. Vi kommer istället att diskutera potentiella modeller med hänseende till detta senare i rapporten. 

För att utföra variabelselektion för båda tidsperioderna undersöker vi VIF-värden, p-värden för variablerna samt $R^2_{adj}$, där vi simultant utför Backward elimination, Forward selection, Stepwise samt Best adjusted $R^2_{adj}$. Resultatet för de bästa modellerna för tidsperiod 1 presenteras i tabellen nedan.

### Period 1

```{r, echo=FALSE}
all_1 <- ols_step_all_possible(model_1)
forward_1 <- ols_step_forward_p(model_1, penter = 0.1)
backward_1 <- ols_step_backward_p(model_1, prem = 0.1)
both_1 <- ols_step_both_p(model_1, pent = 0.1, prem = 0.1)
```

```{r, echo=FALSE}
model_1a <- lm(sjmo ~ ., data_1 %>% select(sjmo, alko, arblösTot, religio))  # forward
model_1b <- lm(sjmo ~ ., data_1 %>% select(sjmo, alko, arblösMän, urban))    # backward
model_1c <- lm(sjmo ~ ., data_1 %>% select(sjmo, alko, arblösTot, religio))  # both
model_1d <- lm(sjmo ~ ., data_1 %>% select(sjmo, alko, arblösTot, religio))  # r sq adj
model_1e <- lm(sjmo ~ ., data_1 %>% select(sjmo, arblösTot, urban,
                                           skilsmässo,religio))              # r sq adj
```

```{r, echo=FALSE}
# for created table of nested data
nested_data_1 <- data.frame(
  Metod= c(rep("Backward elimination", 3),
           linebreak(rep("Forward selection\nStep-wise (forward)\nBest adj. R sq. 1", 9),
                     align = "l"),
           #rep("Step-wise (forward)", 3),
           #rep("Best adj. R sq. 1", 3),
           rep("Best adj. R sq. 2", 4)),
  
  Variabler = c(names(model_1b$coefficients)[-1],
                sort(rep(names(model_1a$coefficients)[-1], 3)),
                #names(model_1c$coefficients)[-1],
                #names(model_1d$coefficients)[-1],
                names(model_1e$coefficients)[-1]),
  
  VIF = formatC(c(vif(model_1b),
                  rep(vif(model_1a)[1], 3),
                  rep(vif(model_1a)[2], 3),
                  rep(vif(model_1a)[3], 3),
                  #vif(model_1c),
                  #vif(model_1d),
                  vif(model_1e)), digits = 3),
  
  pVärden = formatC(c(summary(model_1b)$coefficients[-1,4],
                      rep(summary(model_1a)$coefficients[-1,4][1], 3),
                      rep(summary(model_1a)$coefficients[-1,4][2], 3),
                      rep(summary(model_1a)$coefficients[-1,4][3], 3),
                      #summary(model_1c)$coefficients[-1,4],
                      #summary(model_1d)$coefficients[-1,4],
                      summary(model_1e)$coefficients[-1,4]), digits = 3),
  
  rSqAdj = formatC(c(rep(summary(model_1b)$adj.r.squared, 3),
                     rep(summary(model_1a)$adj.r.squared, 3),
                     rep(summary(model_1c)$adj.r.squared, 3),
                     rep(summary(model_1d)$adj.r.squared, 3),
                     rep(summary(model_1e)$adj.r.squared, 4)), digits = 3),
  
  . = rep(" ", 16))

# Create a table with kable
table_1 <- nested_data_1 %>%
  kable(format = "latex", escape = FALSE, 
        caption = "Potentiella modeller Period 1 (p-gränser för algo.=0.1)") %>%
  
  #column_spec(column = 1, bold = TRUE) %>% 
  
  # Collapse rows within the "Group" column
  collapse_rows(columns = c(1,2,3,4,5), valign = "middle",
                latex_hline = "major") %>%
  
  # Add some table formatting (optional)
  kable_styling("striped", full_width = FALSE) %>%
  row_spec(0, bold = TRUE, background = "lightgray") %>%
  kable_styling(latex_options = "HOLD_position")


# Display the table
table_1
```

```{r, echo=FALSE}
# dataset 1 adjusted r sq plot
all_1 %>%
ggplot(aes(x=n, y=adjr, label = predictors)) +
  geom_point() +
  geom_point(data=all_1 %>% filter(adjr > 0.626),
             pch=24,
             size=4,
             colour="purple") +
  xlab("Number of variables (1-6)") +
  ylab("Adjusted R squared") +
  ggtitle("Adjusted R squared - all variable constellations Period 1") +
  geom_text(data = all_1 %>% filter(adjr > 0.626),
            vjust=-1, hjust=0.2,
            angle = 15) +
  ylim(0, 0.8)
```



I Tabell 1 ser vi respektive metod, med resulterande modellvärden, som, för att välja variabler, har använts på datamängden som svarar mot period 1 (vi har använt samma metoder för alla datamängder i denna studie). I kolumnen “Variabler” ser vi konstellationen variabler som motsvarande metod resulterade i. De resterande kolumnerna redovisar de värden vi anser vara mest kritiska till valet av en (förklarande) modell.

I tillhörande plot, Figur ???, syns hur vi har gått tillväga för att plocka ut de modeller med högst förklaringsgrad. I denna plot motsvarar en punkt en unik uppsättning av variabler. Således blir det totala antalet punkter $2^6 -1$ (-1 eftersom vi inte har någon tom uppsättning), eftersom vi har sex stycken förklarande variabler. Y-axeln visar $R^2_{adj}$-värdet och således får vi en maxpunkt som svarar mot den uppsättning förklarande variabler med högst förklaringsgrad. I detta fall valde vi att studera de två uppsättningar som hade högst förklaringsgrad, eftersom de gav så pass lika förklaringsgrad.

Vi ser nu från Tabell 1 att Forward selection, Step-wise (both) och Best $R^2_{adj}$ (näst bäst), alla tre, gav samma uppsättning variabler som bästa modell. Då denna modell dessutom innehåller variabeln “Alkoholindex” (samt “Arbetslöshetsindex totalt” och “Religiositetsindex”), kan vi dessutom fastslå ett av syftena med denna studie; finns det ett samband mellan alkohol och självmord? Värdena i Tabell 1 tyder på att alkohol bidrar till att förklara självmordsfrekvensen län sinsemellan under period 1 (1963-1965).

Det ska dock nämnas att, även om p-värdena inte är perfekta, så antyder den sista raden i Tabell 1 att det finns en modell som inte inkluderar alkohol som förklarande variabel, men som ändå verkar kunna förklara självmordsfrekvensen. Det kan finnas viss kolinjäritet mellan de förklarande variablerna (alkohol kontra urban, skilsmässa, religion) som med vår data är omöjlig att “trassla” ut.  Mer om detta i slutet av rapporten.

Vidare har vi också helt ignorerat förekomsten av inflytelserika observationer i denna del helt och hållet. Vi har valt att göra på det här sättet eftersom vi saknar domänkunskap helt och hållet i detta projekt. Vi anser att det hade varit för spekulativt att studera de här och har istället skapat en egen sektion av rapporten som är helt dedikerat till inflytelserika observationer och vad som händer om man tar bort dem.

Den har dessutom väldigt låga VIF-värden, näst-högst $R^2_{adj}$ 

```{r}
(lm(data=data_1, formula = sjmo ~ alko + arblösTot + religio ))
(lm(data=data_1, formula = sjmo ~ skilsmässo + arblösTot + religio + urban ))

``` 

Om vi tittar på estimationerna av variablerna för den sista modellen ser vi att den estimationen för urbaniseringsindex är nära 0, alltså att den har relativt liten påverkan på självmord. Den största skillnaden för de två modellerna är att den ena har med skillsmässoindex och den andra har med alkoholindex. Både modellen med alkoholindex och modellen med skillmässoindex är bra förklaringsmodeller för självmordsindex. Det är också värt att notera att dessa är två variabler som är ganska högt korrelerade.

För att ytterligare stärka dessa modeller, undersöker vi hur deras residualer ser ut för att försäkra oss att de inte indikerar problem. 


### Residualplottar - Period 1

```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(2,3), mar = c(5,4,4,2)-0.2, oma = c(0,0,2.3,0), cex.lab=0.9)
plot_predicted_residuals(model_1c, "Mot predikterade")
plot_qq(model_1c, "Normal-QQ plot")

plot.new()

plot(residuals(model_1c) ~ data_1$arblösTot, 
     xlab = "arbetslöshetsindex total",
     ylab = "residualer",
     main = "Mot arbetslöshet")
abline(0,0) 
plot(residuals(model_1c) ~ data_1$alko, 
     xlab = "alkoholindex",
     ylab = "",
     main = "Mot alkohol")
abline(0,0) 
plot(residuals(model_1c) ~ data_1$religio, 
     xlab = "religiositetsindex",
     ylab = "",
     main = "Mot religiositet")
abline(0,0)

mtext("Residualplottar för modell med alkohol, \n arbetslöshet (total) och religiositet (period 1)", side = 3, line = -1, outer = TRUE, font = 2)
```

I Figur 9 ser vi att Residualerna mot predikterade värden ser bra ut, vi kan inte se någon tydlig heteroskedasticitet eller tecken på icke-linjäritet. Normal QQ-plotten visar att residualerna är förhållandevis normalfördelade. Det finns en tendens till avvikelse från linjen till vänster, men den är inte tillräckligt tydlig för att underkänna plotten. Plottarna med residualer mot respektive variabel ser också bra ut. Spridningen längs residualer = 0 ser ut att vara jämnt fördelad och det finns inget tydligt samband med residualerna.

### Period 2

```{r, echo=FALSE}
all_2 <- ols_step_all_possible(model_2)
forward_2 <- ols_step_forward_p(model_2, penter = 0.1)
backward_2 <- ols_step_backward_p(model_2, prem = 0.1)
both_2 <- ols_step_both_p(model_2, pent = 0.1, prem = 0.1)
```

```{r, echo=FALSE}
model_2a <- lm(sjmo ~ ., data_2 %>% select(sjmo, alko, urban))          # forward
model_2b <- lm(sjmo ~ ., data_2 %>% select(sjmo, alko, arblösMän))     # backward
model_2c <- lm(sjmo ~ ., data_2 %>% select(sjmo, alko, urban))          # both
model_2d <- lm(sjmo ~ ., data_2 %>% select(sjmo, arblösMän, arblösTot, religio,
                                           urban, skilsmässo))          # r sq adj
model_2e <- lm(sjmo ~ ., data_2 %>% select(sjmo, arblösTot, urban, skilsmässo,
                                          religio))                     # r sq adj
```



```{r, echo=FALSE}
# for created table of nested data
nested_data_2 <- data.frame(
  Metod= c(rep("Backward elimination", 2),
           linebreak(rep("Forward selection\nStep-wise (forward)", 4),
                     align = "l"),
           #rep("Step-wise (forward)", 2),
           rep("Best adj. R sq. 1", 5),
           rep("Best adj. R sq. 2", 4)),
  
  Variabler = c(names(model_2b$coefficients)[-1],
                sort(rep(names(model_2a$coefficients)[-1], 2)),
                #names(model_2c$coefficients)[-1],
                names(model_2d$coefficients)[-1],
                names(model_2e$coefficients)[-1]),
  
  VIF = formatC(c(vif(model_2b),
                  vif(model_2a),
                  vif(model_2c),
                  vif(model_2d),
                  vif(model_2e)), digits = 3),
  
  pVärden = formatC(c(summary(model_2b)$coefficients[-1,4],
                      sort(rep(summary(model_2a)$coefficients[-1,4],2)),
                      #summary(model_2c)$coefficients[-1,4],
                      summary(model_2d)$coefficients[-1,4],
                      summary(model_2e)$coefficients[-1,4]), digits = 3),
  
  rSqAdj = formatC(c(rep(summary(model_2b)$adj.r.squared, 2),
                     rep(summary(model_2a)$adj.r.squared, 2),
                     rep(summary(model_2c)$adj.r.squared, 2),
                     rep(summary(model_2d)$adj.r.squared, 5),
                     rep(summary(model_2e)$adj.r.squared, 4)), digits = 3),
  
  . = rep(" ", 15))

# Create a table with kable
table_2 <- nested_data_2 %>%
  kable(format = "latex", escape = FALSE, 
        caption = "Potentiella modeller Period 2 (p-gränser för algo.=0.1)") %>%
  
  # Collapse rows within the "Group" column
  collapse_rows(columns = c(1,2,3,4,5), valign = "middle",
                latex_hline = "major") %>%
  
  # Add some table formatting (optional)
  kable_styling("striped", full_width = FALSE) %>%
  row_spec(0, bold = TRUE, background = "lightgray") %>%
  kable_styling(latex_options = "HOLD_position")


# Display the table
table_2
```

```{r, echo=FALSE}
# dataset 2 adjusted r sq plot
all_2 %>%
ggplot(aes(x=n, y=adjr, label = predictors)) +
  geom_point() +
  geom_point(data=all_2 %>% filter(adjr > 0.66),
             pch=24,
             size=4,
             colour="purple") +
  xlab("Number of variables (1-6)") +
  ylab("Adjusted R squared") +
  ggtitle("Adjusted R squared - all variable constellations Period 2") +
  geom_text(data = all_2 %>% filter(adjr > 0.66),
            vjust=-1, hjust=0.2,
            angle = 18) +
  ylim(0, 0.9) +
  xlim(1, 8)
```



I Tabell 2 kan vi observera resultaten för samma process för period 2. Vi kan se att modellen med högst  $R^2_{adj}$ också har väldigt höga VIF-värden. Därför exkluderar vi denna från de potentiellt bästa modellerna. Däremot har modellen med näst högst $R^2_{adj}$ relativt bra VIF och relativt låga p-värden. Denna modell har arbetslöshetsindex, urbaniseringindex, religionsindex och skilsmässoindex som förklarande variabler, vilket även var en av de bästa modellerna för period 1. Vi har alltså inte med alkoholindex i den bästa modellen. Vi kan dock notera att för alla stegvisa metoder så har en modell med alkoholindex tagits fram, dessa har dock ganska låg förklaringsgrad. 

Det skiljer sig alltså lite mellan period 1 och 2. Vi skulle potentiellt kunna få fram en bra modell genom att byta ut skilsmässoindex och alkohol i modellen: 

```{r} 
summary(lm(data=data_2, formula = sjmo ~ alko + arblösTot + religio + urban))
```  
men förklaringsgraden blir då märkbart sämre. 





### Residualplottar - Period 2

```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(2,3), mar = c(5,4,4,2), oma = c(0,0,2,0), cex.lab=0.9)
plot_predicted_residuals(model_2e, "Residualer mot prediktrade")
plot_qq(model_2e, "Normal-QQ plot")

plot(residuals(model_2e) ~ data_2$arblösTot, 
     xlab = "arbetslöshetsindex total",
     ylab = "residualer",
     main = "Mot arbetslöshet")
abline(0,0) 
plot(residuals(model_2e) ~ data_2$urban, 
     xlab = "urbaniseringsindex",
     ylab = "residualer",
     main = "Mot urbanisering")
abline(0,0) 
plot(residuals(model_2e) ~ data_2$skilsmässo, 
     xlab = "skilsmässoindex",
     ylab = "",
     main = "Mot skilsmässor")
abline(0,0) 
plot(residuals(model_2e) ~ data_2$religio, 
     xlab = "religiositetsindex",
     ylab = "",
     main = "Mot religiositet")
abline(0,0)

mtext("Residualplottar för modell med urbaniering, arbetslöshet (total), \n skilsmässor och religiositet (period 2)", side = 3, line = - 1, outer = TRUE, font = 2)

```



I Figur 10 ser vi att residualerna mot predikterade värden ser ganska bra ut, vi kan inte se någon tydlig heteroskedasticitet. Som vi tidigare sett i figur(???) finns det en viss antydan till icke-linjäritet, vi bedömer dock att denna är försumbar och att residualerna är godtagbara (se avsnittet om residualer & transformation). Normal QQ-plotten ser okej ut, men det är svårt att avgöra då vi har en begränsad mängd data. Vi bedömer därför att residualerna verkar vara approximativt normalfördelade ut.

## Inflytelserika observationer

Då vi inte har någon insyn i datainsamlingen och dessutom saknar domänkunskap bör vi vara mycket försiktiga med att ta bort inflytelserika eller tvivelaktiga observationer. Vi vill dock undersöka vad det finns för inflytelserika observationer samt hur de kan påverka modellvalet. Då inflytelserika observationer kan ha en stark påverkan på de förklarande variablerna i en modell är det motiverat att undersöka ifall det finns observationer som står ut. För att undersöka graden av inflytelse kan vi använda Cook’s Distance, där ett högt värde tyder på en hög grad av inflytande, och alltså kan vara en potentiell outlier. 

### Period 1 - utan Jönköpings län

```{r, echo=FALSE, fig.cap = "Cook's distance plot"}
ols_plot_cooksd_bar(model_1)
```



Figur 11 visar vilka observationer som är inflytelserika med ett tröskelvärde på 0.16 för period 1. Från figuren kan vi avläsa att Jönköpings län är den mest inflytelserika observationen, följt av Stockholms län. Jönköping har väldigt högt religiositetsindex under tidsperiod 1 (1963-1965), samtidigt som självmordindexet inte är särskilt lågt. Den andra observationen som är inflytelserik är från Stockholms län, men då denna observation precis överstiger tröskelvärdet väljer vi att endast fokusera på Jönköping. 

Då vi inte vet ifall dessa observationer är outliers eller inte kan vi inte avgöra om de borde exkluderas från modellen. På grund av detta kan vi endast spekulera och skapa hypotetiska modeller, utan att veta ifall de kan och borde appliceras på verkligheten. På grund av tidsramen av detta projekt testar vi att endast ta bort den observation med högst Cooks avstånd för att se hur det påverkar modellvalet. 

För period 1 väljer vi alltså att exkludera Jönköping län för att se ifall det påverkar modellvalet och dess värden. Vi utför samma simultana utvärdering likt tidigare och presenterar resultatet för de bästa modellerna i tabellen nedan. 


```{r, echo=FALSE}
# remove jönköpings län
data_1_red <- data_1 %>% filter(län != 6)
model_1_red <- lm(sjmo ~ ., data = data_1_red %>% select(!län))
```

```{r, echo=FALSE}
all_1_red <- ols_step_all_possible(model_1_red)
forward_1_red <- ols_step_forward_p(model_1_red, penter = 0.1)
backward_1_red <- ols_step_backward_p(model_1_red, prem = 0.1)
both_1_red <- ols_step_both_p(model_1_red, pent = 0.1, prem = 0.1)
```

```{r, echo=FALSE}
model_1a_red <- lm(sjmo ~ ., data_1_red %>% select(sjmo, religio, arblösTot,
                                                   skilsmässo, urban))      # forward
model_1b_red <- lm(sjmo ~ ., data_1_red %>% select(sjmo, arblösTot, alko))  # backward
model_1c_red <- lm(sjmo ~ ., data_1_red %>% select(sjmo, religio, arblösTot,
                                               skilsmässo, urban))          # both
model_1d_red <- lm(sjmo ~ ., data_1_red %>% select(sjmo, arblösMän, urban,
                                               skilsmässo, religio))        # r sq adj
```



```{r, echo=FALSE}
nested_data_1_red <- data.frame (
  Metod= c(rep("Backward elimination", 2),
           linebreak(rep("Forward selection\nStep-wise (forward)", 8),
                     align = "l"),
           #rep("Step-wise (forward)", 4),
           rep("Best adj. R sq.", 4)),
  
  Variabler = c(names(model_1b_red$coefficients)[-1],
                rep(names(model_1a_red$coefficients)[-1][1], 2),
                rep(names(model_1a_red$coefficients)[-1][2], 2),
                rep(names(model_1a_red$coefficients)[-1][3], 2),
                rep(names(model_1a_red$coefficients)[-1][4], 2),
                names(model_1d_red$coefficients)[-1]),
  
  VIF = formatC(c(vif(model_1b_red),
                  rep(vif(model_1a_red)[1], 2),
                  rep(vif(model_1a_red)[2], 2),
                  rep(vif(model_1a_red)[3], 2),
                  rep(vif(model_1a_red)[4], 2),
                  vif(model_1d_red)), digits = 3),
  
  pVärden = formatC(c(summary(model_1b_red)$coefficients[-1,4],
                      rep(summary(model_1a_red)$coefficients[-1,4][1], 2),
                      rep(summary(model_1a_red)$coefficients[-1,4][2], 2),
                      rep(summary(model_1a_red)$coefficients[-1,4][3], 2),
                      rep(summary(model_1a_red)$coefficients[-1,4][4], 2),
                      summary(model_1d_red)$coefficients[-1,4]), digits = 3),
  
  rSqAdj = formatC(c(rep(summary(model_1b_red)$adj.r.squared, 2),
                     rep(summary(model_1a_red)$adj.r.squared, 4),
                     rep(summary(model_1c_red)$adj.r.squared, 4),
                     rep(summary(model_1d_red)$adj.r.squared, 4)), digits = 3),
  
  . = rep(" ", 14))

# Create a table with kable
table_1_red <- nested_data_1_red %>%
  kable(format = "latex", escape = FALSE, 
        caption = "Potentiella modeller Period 1 Jönköpings län borttaget
        (p-gränser för algo.=0.1)") %>%
  
  #column_spec(column = 1, bold = TRUE) %>% 
  
  # Collapse rows within the "Group" column
  collapse_rows(columns = c(1,2,3,4,5), valign = "middle") %>%
  
  # Add some table formatting (optional)
  kable_styling("striped", full_width = FALSE) %>%
  row_spec(0, bold = TRUE, background = "lightgray") %>%
  kable_styling(latex_options = "HOLD_position")


# Display the table
table_1_red
```


Från Tabell 3 ser vi att alkohol nu, gentemot Tabell 1, har blivit mindre framträdande som förklarande variabel, och att kombinationen “Urbaniseringsindex”, “Skilsmässoindex” och “Religiositetsindex” tillsammans med “Arbetslöshetsindex” nu ger de klart högsta justerade förklaringsgraderna - nästan 70 % -  en ganska påtaglig ökning från de 63 % vi nådde upp till med alkohol, när Jönköping fortfarande var del av datan. När vi väljer ut just “Arbetslöshetsindex Män” som den fjärde variabeln får vi ganska signifikanta p-värden och även låga VIF-värden. Skulle det nu vara så att vi hade mer domänkunskap, och att Jönköping vore en observation som bör exkluderas, så hade denna modell varit en bra kandidat för att förklara självmordsfrekvensen under period 1 (förutsatt att residualerna ser bra ut).


```{r, echo=FALSE}
# dataset 1 with jönköping removed adjusted r sq plot
all_1_red %>%
ggplot(aes(x=n, y=adjr, label = predictors)) +
  geom_point() +
  geom_point(data=all_1_red %>% filter(adjr > 0.695),
             pch=24,
             size=4,
             colour="purple") +
  xlab("Number of variables (1-6)") +
  ylab("Adjusted R squared") +
  ggtitle("Adjusted R squared - all variable constellations Period 1
          Jönköpings län removed") +
  geom_text(data = all_1_red %>% filter(adjr > 0.695),
            vjust=-1, hjust=0.2,
            angle = 18) +
  ylim(0, 0.9) +
  xlim(1, 8)
```

### Residualplottar Period 1 - utan Jönköpings län

```{r, echo=FALSE, fig.cap="Residualer"}
par(mfrow = c(2,3), mar = c(5,4,4,2), oma = c(0,0,2,0), cex.lab=0.9)
plot_predicted_residuals(model_1d_red, "Residualer mot prediktrade")
plot_qq(model_1d_red, "Normal-QQ plot")

plot(residuals(model_1d_red) ~ data_1_red$arblösMän, 
     xlab = "arbetslöshetsindex män",
     ylab = "residualer",
     main = "Mot arbetslöshet")
abline(0,0) 
plot(residuals(model_1d_red) ~ data_1_red$urban, 
     xlab = "urbaniseringsindex",
     ylab = "residualer",
     main = "Mot urbanisering")
abline(0,0) 
plot(residuals(model_1d_red) ~ data_1_red$skilsmässo, 
     xlab = "skilsmässoindex",
     ylab = "",
     main = "Mot skilsmässor")
abline(0,0) 
plot(residuals(model_1d_red) ~ data_1_red$religio, 
     xlab = "religiositetsindex",
     ylab = "",
     main = "Mot religiositet")
abline(0,0)

mtext("Residualplottar för modell med urbaniering, arbetslöshet (män), \n skilsmässor och religiositet (period 1, utan Jönköping)", side = 3, line = - 1, outer = TRUE, font = 2)

```


I Figur 12 ser vi att residualerna mot predikterade värden ser ganska bra ut, vi kan inte se någon tydlig heteroskedasticitet eller tecken på icke-linjäritet. Normal QQ-plotten visar att residualerna är hyfsat normalfördelade, dock ser de ut att avvika från linjen till vänster. Avvikelsen är dock inte tillräckligt tydlig med tanke på att vi har så få datapunkter. Vi kan därför inte helt förkasta normalfördelningsantagande. Plottarna med residualer mot respektive variabel ser bra ut. Spridningen längs residualer = 0 är hyfsat jämnt fördelad och det finns inget tydligt samband med residualerna.


Nu undersöker vi inflytelserika observationer på samma sätt för period 2 genom att undersöka Cooks avstånd för alla observationer. 

### Period 2 - utan Norrbottens län

```{r, echo=FALSE, warning=FALSE, fig.cap="Cook's distance plot"}
ols_plot_cooksd_bar(model_2)
```


I Figur 13 kan vi observera att det finns fyra inflytelserika observationer som överstiger tröskelvärdet på 0.16 för period 2. Dessa observationer har dock inte lika höga Cooks avstånd som observationerna för period 1. Den observation med högst värde är Norrbotten län, detta på grund av hög arbetslöshetsindex både för män och totalt. Näst högst Cooks avstånd har Jönköping län som har ett högt religiositetindex, efter det följer Gotlands län och Hallands län där Gotland har låg urbaniseringsindex och Halland har låg arbetslöshetsindex för män.

Likt period 1 kommer vi nu att exkludera den observation med högst Cooks avstånd för period 2, vilket i detta fall är Norrbottens län. Nu gör vi likt tidigare en tabell för de bästa modellerna med det de reducerade datan, resultatet presenteras nedan.


```{r, echo=FALSE}
# remove jönköpings län
data_2_red <- data_2 %>% filter(län != 25)
model_2_red <- lm(sjmo ~ ., data = data_2_red %>% select(!län))
```

```{r, echo=FALSE}
all_2_red <- ols_step_all_possible(model_2_red)
forward_2_red <- ols_step_forward_p(model_2_red, penter = 0.1)
backward_2_red <- ols_step_backward_p(model_2_red, prem = 0.1)
both_2_red <- ols_step_both_p(model_2_red, pent = 0.1, prem = 0.1)
```

```{r, echo=FALSE}
model_2a_red <- lm(sjmo ~ ., data_2_red %>% select(sjmo, alko, urban))      # forward
model_2b_red <- lm(sjmo ~ ., data_2_red %>% select(sjmo, alko, arblösMän))  # backward
model_2c_red <- lm(sjmo ~ ., data_2_red %>% select(sjmo, alko, urban))      # both
model_2d_red <- lm(sjmo ~ ., data_2_red %>% select(sjmo, arblösTot, urban,
                                               skilsmässo, religio))        # r sq adj
```

```{r, echo=FALSE, warning=FALSE}
nested_data_2_red <- data.frame(
  Metod= c(rep("Backward elimination", 2),
           linebreak(rep("Forward selection\nStep-wise (forward)", 4),
                     align = "l"),
           rep("Best adj. R sq.", 4)),
  
  Variabler = c(names(model_2b_red$coefficients)[-1],
                rep(names(model_2a_red$coefficients)[-1][1], 2),
                rep(names(model_2a_red$coefficients)[-1][2], 2),
                names(model_2d_red$coefficients)[-1]),
  
  VIF = formatC(c(vif(model_2b_red),
                  vif(model_2a_red),
                  vif(model_2c_red),
                  vif(model_2d_red)), digits = 3),
  
  pVärden = formatC(c(summary(model_2b_red)$coefficients[-1,4],
                      rep(summary(model_2a_red)$coefficients[-1,4][1], 2),
                      rep(summary(model_2a_red)$coefficients[-1,4][2], 2),
                      summary(model_2d_red)$coefficients[-1,4]), digits = 3),
  
  rSqAdj = formatC(c(rep(summary(model_2b_red)$adj.r.squared, 2),
                     rep(summary(model_2a_red)$adj.r.squared, 2),
                     rep(summary(model_2c_red)$adj.r.squared, 2),
                     rep(summary(model_2d_red)$adj.r.squared, 4)), digits = 3),
  
  . = rep(" ", 10))

# Create a table with kable
nested_table_2_red <- nested_data_2_red %>%
  kable(format = "latex", escape = FALSE, 
        caption = "Potentiella modeller Period 2 Norrbottens län borttaget
        (p-gränser för algo.=0.1)") %>%
  
  #column_spec(column = 1, bold = TRUE) %>% 
  
  # Collapse rows within the "Group" column
  collapse_rows(columns = c(1,2,3,4,5), valign = "middle",
                latex_hline = "major") %>%
  
  # Add some table formatting (optional)
  kable_styling("striped", full_width = FALSE) %>%
  row_spec(0, bold = TRUE, background = "lightgray") %>%
  kable_styling(latex_options = "HOLD_position")


# Display the table
nested_table_2_red
```


I Tabell 4 ser vi i stort sett samma modeller som i Tabell 2 (samma period, fast med komplett data). Alltså bidrog inte detta med speciellt mycket ny info och vi avstår därför från att vidare utforska detta.
Med rätt domänkunskap kanske vi hade kunnat exkludera ytterligare län, men vi avstår från att spekulera ytterligare om detta.


```{r, echo=FALSE, warning=FALSE}
# dataset 2 with norrbotten removed adjusted r sq plot
all_2_red %>%
ggplot(aes(x=n, y=adjr, label = predictors)) +
  geom_point() +
  geom_point(data=all_2_red %>% filter(adjr > 0.685),
             pch=24,
             size=4,
             colour="purple") +
  xlab("Number of variables (1-6)") +
  ylab("Adjusted R squared") +
  ggtitle("Adjusted R squared - all variable constellations Period 2
          Norrbottens län removed") +
  geom_text(data = all_2_red %>% filter(adjr > 0.685),
            vjust=-1, hjust=0.2,
            angle = 18) +
  ylim(0, 0.9) +
  xlim(1, 8)
```


## Diskussion
Det verkar finnas ett samband mellan alkohol och självmord för tidperioderna 1963-65 och 1966-1968 för länen i dataseten. Vi kan däremot inte säga något om orsakssamband. Det skulle kunna finnas en bakomliggande variabel som påverkar både alkoholindex och självmordsfrekvens utan att variablerna egentligen har någon direkt påverkan på varandra, eller att en av de förklarande variablerna har en direkt påverkan på en annan. Exempelvis har vi sett att bland de bästa modellerna finns modeller med bland annat skillsmässoindex och utan alkoholindex som förklarar självmordsfrekvens bra. Vi har även sett att skillsmässoindex och alkoholindex är väldigt korrelerade. Det skulle kunna vara så att skillsmässoindex orsakar både en ökning i självmord och en ökning i alkoholkonsumtion, och att vi därför ser en generell ökning i självmord bland län när alkoholkonsumtion ökar. 

För att kunna urskilja effekterna skulle vi behöva ortogonala data, men då detta dataset är relativt litet och verkar lida av viss kolinjäritet blir det svårt att utforska effekterna ytterligare.


## Reflektion över metodval
Om det finns hög multikolinjäritet i en regressionsmodell kan p-värdena bli opålitliga, vilket är det som metoder för stegvis variabelselektion bygger på för att ta fram modeller. Det kan därför vara problematiskt att vi använde oss av stegvisa metoder för att ta fram modeller, när det fanns mycket korrelation hos våra förklarande variabler. Ett annat sätt att utföra detta projekt hade varit att i början av projektet undersöka $VIF$-värden för alla variabler i en gemensam modell. Genom att göra detta hade vi direkt kunnat utesluta variabler med höga $VIF$-värden för att på detta sätt kunna utesluta förklarande variabler med hög kolinjäritet. Då hade vi inte behövt oroa oss för detta vid ett senare skede i modellvalen och inte behöva reflektera över detta vidare. 

Något vi har noterat med det givna datasetet är att både Stockholm län och Stockholm stad än inkluderade som separata datapunkter. Detta är problematiskt eftersom dessa observationer inte är oberoende, då Stockholm stad är en del av Stockholms län. Vi kan däremot inte fastställa att exkludering av en av dessa datapunkter är föreskriven då vi inte är tillräckligt insatta i betydelsen av varje datapunkt. Det bör däremot ske en utvärdering över hur dessa datapunkter ska användas på ett optimalt sätt för vårt ändamål. På grund av denna ovisshet har vi valt att inte exkludera någon av dessa observationer.

## Slutsats
Sammanfattningsvis har vi fastställt två olika modeller som vi anser är bäst för att förklara självmordsfrekvensen i Sverige under perioden år 1963-1965 samt 1966-1968. Utan att ta hänsyn till inflytelserika observationer har vi tagit fram en modell för respektive tidsperiod där den första har förklarande variabler alkoholindex, religiositetsindex och arbetslöshetsindex total och den andra har förklarande variabler religiositetsindex, urbaniseringsindex, skilsmässoindex och arbetslöshetsindex total. Sammantaget är det inte självklart vilka variabler som bäst förklarar variationen i självmordsfrekvens mellan länen då variablerna skiljer sig mellan tidsperioderna. Alkoholindex verkar kunna vara en bra förklarande faktor men kan bytas ut mot skilsmässoindex och urbaniseringsindex, då dessa variabler också kan förklara variationen i självmordsfrekvensen mellan länen (tillsammans med arbetslöshet total). 


